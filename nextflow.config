manifest {
  name = 'REPSET'
  version = 'not set'
  author = 'Rad Suchecki et al.'
  homePage = 'https://github.com/csiro-crop-informatics/repset'
  description = 'Reproducible aligner evaluation workflow'
  defaultBranch = 'master'
  nextflowVersion = '!>=19.10.0' //due to https://github.com/nextflow-io/nextflow/issues/1015 fix which prevents failure when (internal) list of either RNA or DNA aligners empty
}



// // // Global default params
params {
  release = false //if true and GH_TOKEN set in environment and executed from repo then (1) create release, (2) upload results and meta artefacts (3) finalise release to trigger zenodo build
  draft = false //if true and --release (see above) then the generated GH release will be a draft one
  outdir = "./results"
  infodir = "./flowinfo"
  singularitydir = "./singularity-images"
  publishmode = "copy"
  debug = false  //set true for quicker runs on subset data
  subset = -1 //only run for the first n reference data sets
  samplesReal = -1 //only run for the first n reference data sets
  // reads = 'realRNA|simulatedRNA|realDNA|simulatedDNA'

  justvalidate = false // if true exit immediatelly after validation
  mappers = 'all'
  mapmode = 'rna2rna|rna2dna|dna2dna'
  one_thread_idx = 'bwa|dart|gsnap|kallisto|subread' //these mappers do not mutli-thread the indexing process, so lets not over-allocate resources

  //Evlauation params
  allowedDelta = 5 //e.g. use --allowed-delta 100 to treat a read as correctly mapped if a coordinate falls up to 100 bp outside its expected position
}

//Default inputs for Simulations
includeConfig 'conf/simulations.config'

//Default real reads spec
includeConfig 'conf/real_reads.config'

//Default params for aligners
includeConfig 'conf/mappers.config'
includeConfig 'conf/mapping_params.config'

//Output files conf
includeConfig 'conf/publish.config'

//Compute requirements, CPUs, RAM, time
includeConfig 'conf/requirements.config'

//Global and process specific container conf
includeConfig 'conf/containers.config'

process {
  cache = 'lenient'
  errorStrategy = { params.debug ? 'finish' : (task.attempt < process.maxRetries ? 'retry' : 'ignore') }
  maxRetries = 2
}

profiles {
  docker {
      docker {
        enabled = true
        //fixOwnership = true
        docker.runOptions = '-u $(id -u):$(id -g)'
    }
  }
  awsbatch {
    aws.region = 'ap-southeast-2'
    aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
    process {
      executor = 'awsbatch'
      queue = 'flowq'
      withLabel: '.*groovy.*' {
        container = 'rsuchecki/groovy-conda-samtools:0.1' //currently not able to find aws cli when using container based on official groovy - likely requires user/workdir/entry reconf
      }
    }
  }
  slurm {
    process {
      executor = 'slurm'
      scratch = false //why explicit?
      withLabel: 'rscript|rrender' {
        executor =  'local'
      }
    }
  }
  singularity {
    singularity {
      enabled = true
      autoMounts = true
      cacheDir = "${params.singularitydir}"  //when distibuting the pipeline probably should point under $workDir
    }
    process {
      withLabel: '.*groovy.*' {
        containerOptions = '-B "$PWD":/home/groovy/.groovy'  //otherwise grabbing grapes may fail with read-only filesystem error
      }
    }
  }
  CI {
    docker.runOptions = '-u root:root' //apparently required for GH actions but only causes problems with process using bin/paf2pretzel.groovy due to Ivy limitations
    process {
      errorStrategy = 'terminate'
      maxRetries = 0
    }
  }
}

//GENERATE REPORT https://www.nextflow.io/docs/latest/tracing.html#trace-report
report {
    enabled = true
    file = "${params.infodir}/report.html"
}

//GENERATE TIMELINE https://www.nextflow.io/docs/latest/tracing.html#timeline-report
timeline {
    enabled = true
    timeline.file = "${params.infodir}/timeline.html"
}

//GENERATE PIPELINE TRACE https://www.nextflow.io/docs/latest/tracing.html#trace-report
trace {
    enabled = true
    raw	= true //date and time are reported as milliseconds and memory as number of bytes
    file = "${params.infodir}/trace.tsv"
    fields = 'task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes'
}

//GENERATE GRAPH REPRESENTATION OF THE PIPELINE FLOW
dag {
    enabled = true
    file = "${params.infodir}/dag.png"
}